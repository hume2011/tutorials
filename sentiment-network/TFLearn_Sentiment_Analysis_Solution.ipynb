{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with TFLearn\n",
    "\n",
    "In this notebook, we'll continue Andrew Trask's work by building a network for sentiment analysis on the movie review data. Instead of a network written with Numpy, we'll be using [TFLearn](http://tflearn.org/), a high-level library built on top of TensorFlow. TFLearn makes it simpler to build networks just by defining the layers. It takes care of most of the details for you.\n",
    "\n",
    "We'll start off by importing all the modules we'll need, then load and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Following along with Andrew, our goal here is to convert our reviews into word vectors. The word vectors will have elements representing words in the total vocabulary. If the second position represents the word 'the', for each review we'll count up the number of times 'the' appears in the text and set the second position to that count. I'll show you examples as we build the input data from the reviews data. Check out Andrew's notebook and video for more about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "Use the pandas library to read the reviews and postive/negative labels from comma-separated files. The data we're using has already been preprocessed a bit and we know it uses only lower case characters. If we were working from raw data, where we didn't know it was all lower case, we would want to add a step here to convert it. That's so we treat different variations of the same word, like `The`, `the`, and `THE`, all the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('reviews.txt', header=None)\n",
    "labels = pd.read_csv('labels.txt', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting word frequency\n",
    "\n",
    "To start off we'll need to count how often each word appears in the data. We'll use this count to create a vocabulary we'll use to encode the review data. This resulting count is known as a [bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model). We'll use it to select our vocabulary and build the word vectors. You should have seen how to do this in Andrew's lesson. Try to implement it here using the [Counter class](https://docs.python.org/2/library/collections.html#collections.Counter).\n",
    "\n",
    "> **Exercise:** Create the bag of words from the reviews data and assign it to `total_counts`. The reviews are stores in the `reviews` [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). If you want the reviews as a Numpy array, use `reviews.values`. You can iterate through the rows in the DataFrame with `for idx, row in reviews.iterrows():` ([documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html)). When you break up the reviews into words, use `.split(' ')` instead of `.split()` so your results match ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in data set:  74074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'': 1111930,\n",
       "         'zir': 2,\n",
       "         'chiropractor': 1,\n",
       "         'kasturba': 7,\n",
       "         'dhol': 10,\n",
       "         'dailies': 4,\n",
       "         'uprosing': 1,\n",
       "         'tenets': 5,\n",
       "         'orchestrates': 3,\n",
       "         'adhered': 2,\n",
       "         'montalban': 9,\n",
       "         'drummers': 2,\n",
       "         'splendini': 4,\n",
       "         'ethnicity': 15,\n",
       "         'servicable': 1,\n",
       "         'nutz': 1,\n",
       "         'wrangling': 2,\n",
       "         'butterick': 1,\n",
       "         'fugitives': 4,\n",
       "         'parade': 78,\n",
       "         'unrevealed': 3,\n",
       "         'preferably': 37,\n",
       "         'silvestro': 3,\n",
       "         'futurama': 4,\n",
       "         'channy': 1,\n",
       "         'survivors': 101,\n",
       "         'seducing': 25,\n",
       "         'fele': 1,\n",
       "         'thoughtfulness': 6,\n",
       "         'nba': 11,\n",
       "         'refutation': 1,\n",
       "         'indisputably': 2,\n",
       "         'unnoticeable': 2,\n",
       "         'luigi': 12,\n",
       "         'juan': 52,\n",
       "         'astral': 9,\n",
       "         'gentile': 5,\n",
       "         'pees': 3,\n",
       "         'keitel': 36,\n",
       "         'mayo': 5,\n",
       "         'seor': 2,\n",
       "         'erfoud': 2,\n",
       "         'kingmaker': 1,\n",
       "         'orbs': 2,\n",
       "         'lis': 3,\n",
       "         'ricca': 2,\n",
       "         'favoritism': 1,\n",
       "         'toreton': 1,\n",
       "         'comotose': 1,\n",
       "         'medicals': 1,\n",
       "         'tribune': 1,\n",
       "         'avoidance': 9,\n",
       "         'punning': 1,\n",
       "         'grenades': 15,\n",
       "         'quadrilateral': 1,\n",
       "         'instill': 11,\n",
       "         'meatheads': 1,\n",
       "         'metcalfe': 5,\n",
       "         'aod': 3,\n",
       "         'friendliness': 3,\n",
       "         'goran': 6,\n",
       "         'quitte': 3,\n",
       "         'thousands': 153,\n",
       "         'stellwaggen': 1,\n",
       "         'brumes': 1,\n",
       "         'pak': 5,\n",
       "         'resumed': 10,\n",
       "         'wearily': 3,\n",
       "         'adjusting': 8,\n",
       "         'aetherial': 1,\n",
       "         'deadbeats': 1,\n",
       "         'transfers': 11,\n",
       "         'saver': 2,\n",
       "         'garris': 9,\n",
       "         'condoleeza': 2,\n",
       "         'darwinism': 2,\n",
       "         'mushed': 4,\n",
       "         'splainin': 1,\n",
       "         'photographing': 11,\n",
       "         'baaaad': 1,\n",
       "         'hausman': 1,\n",
       "         'pomeranz': 1,\n",
       "         'workhorse': 2,\n",
       "         'exposing': 32,\n",
       "         'unlocked': 6,\n",
       "         'leaner': 3,\n",
       "         'elder': 37,\n",
       "         'rookery': 1,\n",
       "         'amiss': 3,\n",
       "         'parley': 1,\n",
       "         'whichever': 21,\n",
       "         'fastbreak': 1,\n",
       "         'rehabbed': 1,\n",
       "         'undressing': 5,\n",
       "         'poopchev': 1,\n",
       "         'jerilee': 1,\n",
       "         'snack': 13,\n",
       "         'daddies': 2,\n",
       "         'michel': 33,\n",
       "         'hieroglyphs': 1,\n",
       "         'longlost': 1,\n",
       "         'harmoniously': 1,\n",
       "         'consider': 513,\n",
       "         'skittles': 4,\n",
       "         'geraldine': 26,\n",
       "         'ashkenazi': 3,\n",
       "         'rox': 1,\n",
       "         'bicarbonate': 2,\n",
       "         'poppy': 3,\n",
       "         'clearlly': 1,\n",
       "         'hiker': 11,\n",
       "         'ellipses': 2,\n",
       "         'boyars': 1,\n",
       "         'beth': 39,\n",
       "         'wag': 4,\n",
       "         'dooget': 2,\n",
       "         'gayness': 2,\n",
       "         'gourmets': 1,\n",
       "         'blythe': 6,\n",
       "         'dynamics': 53,\n",
       "         'mo': 36,\n",
       "         'morvern': 20,\n",
       "         'senshi': 1,\n",
       "         'chairs': 24,\n",
       "         'wavers': 6,\n",
       "         'minimising': 1,\n",
       "         'newsman': 4,\n",
       "         'syndicated': 11,\n",
       "         'jerol': 1,\n",
       "         'drenching': 2,\n",
       "         'phillipine': 1,\n",
       "         'logics': 2,\n",
       "         'sloppiness': 10,\n",
       "         'ottiano': 1,\n",
       "         'unappealing': 46,\n",
       "         'ru': 2,\n",
       "         'marital': 32,\n",
       "         'kuchler': 1,\n",
       "         'compulsively': 6,\n",
       "         'appraisals': 1,\n",
       "         'burger': 13,\n",
       "         'westernbend': 1,\n",
       "         'ravage': 4,\n",
       "         'psychotic': 120,\n",
       "         'equidor': 1,\n",
       "         'petzold': 3,\n",
       "         'yami': 3,\n",
       "         'gelled': 4,\n",
       "         'hoisting': 1,\n",
       "         'russians': 39,\n",
       "         'whitmore': 4,\n",
       "         'rem': 1,\n",
       "         'lavish': 55,\n",
       "         'ply': 3,\n",
       "         'rsther': 1,\n",
       "         'excitied': 1,\n",
       "         'polay': 4,\n",
       "         'brainiac': 6,\n",
       "         'rosamunde': 1,\n",
       "         'puffed': 5,\n",
       "         'churidar': 1,\n",
       "         'reemergence': 2,\n",
       "         'maraglia': 1,\n",
       "         'moron': 57,\n",
       "         'bayonets': 2,\n",
       "         'haaaaaaaa': 1,\n",
       "         'pies': 11,\n",
       "         'nunsploit': 2,\n",
       "         'dainton': 2,\n",
       "         'admission': 44,\n",
       "         'connery': 94,\n",
       "         'resmblance': 1,\n",
       "         'afterward': 55,\n",
       "         'tremors': 32,\n",
       "         'anan': 1,\n",
       "         'ripper': 28,\n",
       "         'shingo': 1,\n",
       "         'advise': 90,\n",
       "         'ineffectual': 14,\n",
       "         'eulogy': 9,\n",
       "         'humor': 1309,\n",
       "         'bodega': 2,\n",
       "         'plusthe': 1,\n",
       "         'rydstrom': 1,\n",
       "         'hjejle': 1,\n",
       "         'denouements': 1,\n",
       "         'corporation': 62,\n",
       "         'newscast': 2,\n",
       "         'sockets': 8,\n",
       "         'culminating': 31,\n",
       "         'panty': 3,\n",
       "         'menalaus': 1,\n",
       "         'prove': 265,\n",
       "         'hampshire': 7,\n",
       "         'dammes': 4,\n",
       "         'atmospheric': 148,\n",
       "         'metamorphosing': 1,\n",
       "         'bmws': 2,\n",
       "         'vuchella': 1,\n",
       "         'freebasing': 1,\n",
       "         'thicko': 1,\n",
       "         'unrelatable': 1,\n",
       "         'gautum': 1,\n",
       "         'faylen': 1,\n",
       "         'vacant': 19,\n",
       "         'kittredge': 2,\n",
       "         'unbelieveablity': 1,\n",
       "         'lighter': 60,\n",
       "         'yoshinaga': 5,\n",
       "         'mcguther': 1,\n",
       "         'debatably': 2,\n",
       "         'spokane': 1,\n",
       "         'surrendering': 4,\n",
       "         'kellerman': 16,\n",
       "         'durbin': 36,\n",
       "         'identifiable': 14,\n",
       "         'imbues': 7,\n",
       "         'cannom': 1,\n",
       "         'paytv': 1,\n",
       "         'baransky': 1,\n",
       "         'thang': 3,\n",
       "         'hampers': 4,\n",
       "         'viel': 8,\n",
       "         'penitentiaries': 1,\n",
       "         'ostentatious': 3,\n",
       "         'lightsabre': 1,\n",
       "         'byran': 1,\n",
       "         'negre': 1,\n",
       "         'atually': 1,\n",
       "         'metallica': 4,\n",
       "         'wasabi': 1,\n",
       "         'levels': 235,\n",
       "         'likens': 2,\n",
       "         'chou': 21,\n",
       "         'danis': 3,\n",
       "         'dabbling': 4,\n",
       "         'illogic': 2,\n",
       "         'jerman': 2,\n",
       "         'angela': 85,\n",
       "         'roby': 1,\n",
       "         'hodgensville': 1,\n",
       "         'fleeing': 36,\n",
       "         'supremacist': 6,\n",
       "         'goforth': 1,\n",
       "         'dispised': 1,\n",
       "         'insupportable': 1,\n",
       "         'mandates': 2,\n",
       "         'wits': 34,\n",
       "         'exhalation': 1,\n",
       "         'stolz': 6,\n",
       "         'cushionantonietta': 1,\n",
       "         'brideshead': 5,\n",
       "         'bosworth': 20,\n",
       "         'smugness': 10,\n",
       "         'impolite': 1,\n",
       "         'squandered': 24,\n",
       "         'founders': 3,\n",
       "         'upto': 2,\n",
       "         'rumah': 1,\n",
       "         'backgroundother': 1,\n",
       "         'portabello': 3,\n",
       "         'geological': 3,\n",
       "         'seychelles': 1,\n",
       "         'braggart': 1,\n",
       "         'roadtrip': 1,\n",
       "         'panda': 11,\n",
       "         'gunman': 17,\n",
       "         'international': 266,\n",
       "         'amaturish': 1,\n",
       "         'leos': 2,\n",
       "         'pixilated': 1,\n",
       "         'attendant': 40,\n",
       "         'backyard': 35,\n",
       "         'fonterbras': 1,\n",
       "         'dimensionally': 7,\n",
       "         'emplacement': 1,\n",
       "         'verbalizations': 1,\n",
       "         'arbor': 4,\n",
       "         'simpathetic': 2,\n",
       "         'kiesler': 3,\n",
       "         'refute': 3,\n",
       "         'bother': 396,\n",
       "         'meanders': 24,\n",
       "         'vegetation': 5,\n",
       "         'philandering': 8,\n",
       "         'cammie': 1,\n",
       "         'kristoffer': 2,\n",
       "         'object': 142,\n",
       "         'defibulator': 1,\n",
       "         'sainthood': 2,\n",
       "         'danira': 1,\n",
       "         'eads': 2,\n",
       "         'sachs': 6,\n",
       "         'zenith': 11,\n",
       "         'cheesiest': 20,\n",
       "         'overstayed': 2,\n",
       "         'formidably': 3,\n",
       "         'olosio': 1,\n",
       "         'adenine': 1,\n",
       "         'wrecking': 13,\n",
       "         'hadda': 1,\n",
       "         'narsil': 1,\n",
       "         'consisting': 31,\n",
       "         'indoctrinate': 2,\n",
       "         'stability': 13,\n",
       "         'philospher': 1,\n",
       "         'solved': 43,\n",
       "         'watered': 35,\n",
       "         'portraying': 227,\n",
       "         'ksxy': 2,\n",
       "         'voc': 1,\n",
       "         'stroup': 4,\n",
       "         'proctor': 1,\n",
       "         'timeslot': 1,\n",
       "         'roo': 7,\n",
       "         'puberty': 19,\n",
       "         'linkage': 4,\n",
       "         'misinterprets': 1,\n",
       "         'unfolding': 47,\n",
       "         'quartet': 23,\n",
       "         'extrication': 1,\n",
       "         'alumna': 1,\n",
       "         'conformed': 1,\n",
       "         'piemaker': 2,\n",
       "         'vizio': 1,\n",
       "         'politely': 17,\n",
       "         'touching': 435,\n",
       "         'marsalis': 1,\n",
       "         'document': 54,\n",
       "         'hoth': 1,\n",
       "         'scorcesee': 2,\n",
       "         'absorption': 6,\n",
       "         'bonaerense': 1,\n",
       "         'quoit': 1,\n",
       "         'villainous': 46,\n",
       "         'boro': 7,\n",
       "         'livinston': 1,\n",
       "         'glushko': 1,\n",
       "         'forty': 103,\n",
       "         'grue': 1,\n",
       "         'combusting': 2,\n",
       "         'polley': 1,\n",
       "         'penneys': 1,\n",
       "         'gentlemanlike': 1,\n",
       "         'innovatively': 2,\n",
       "         'holly': 107,\n",
       "         'silouhettes': 1,\n",
       "         'energised': 1,\n",
       "         'swinged': 1,\n",
       "         'streetwalkers': 1,\n",
       "         'tvone': 1,\n",
       "         'animaster': 1,\n",
       "         'bona': 16,\n",
       "         'soprana': 1,\n",
       "         'conflagration': 2,\n",
       "         'fraught': 13,\n",
       "         'filmaking': 4,\n",
       "         'sangrou': 1,\n",
       "         'broadcasted': 2,\n",
       "         'emile': 11,\n",
       "         'tumpangan': 1,\n",
       "         'sachetti': 1,\n",
       "         'gerards': 1,\n",
       "         'magnolias': 4,\n",
       "         'yna': 3,\n",
       "         'lumsden': 1,\n",
       "         'egyptologists': 1,\n",
       "         'necked': 1,\n",
       "         'scenification': 1,\n",
       "         'utter': 240,\n",
       "         'filmedan': 1,\n",
       "         'lorri': 2,\n",
       "         'elects': 4,\n",
       "         'dual': 24,\n",
       "         'bachelors': 6,\n",
       "         'consciously': 26,\n",
       "         'tricks': 137,\n",
       "         'duforq': 1,\n",
       "         'conelly': 1,\n",
       "         'dsire': 2,\n",
       "         'terrors': 12,\n",
       "         'silvio': 16,\n",
       "         'recieve': 1,\n",
       "         'finney': 49,\n",
       "         'attentive': 10,\n",
       "         'devices': 75,\n",
       "         'pagels': 1,\n",
       "         'farther': 23,\n",
       "         'bolivarians': 2,\n",
       "         'swag': 3,\n",
       "         'nudgewink': 1,\n",
       "         'incites': 5,\n",
       "         'kin': 12,\n",
       "         'botswana': 2,\n",
       "         'besmirches': 2,\n",
       "         'unrehearsed': 4,\n",
       "         'pathetic': 468,\n",
       "         'surprised': 802,\n",
       "         'extraction': 2,\n",
       "         'stonewashed': 1,\n",
       "         'tranquilli': 1,\n",
       "         'complementing': 2,\n",
       "         'rambos': 2,\n",
       "         'heard': 1111,\n",
       "         'neighbours': 30,\n",
       "         'completists': 17,\n",
       "         'mammy': 11,\n",
       "         'shogun': 10,\n",
       "         'vignette': 15,\n",
       "         'fourth': 176,\n",
       "         'cherri': 1,\n",
       "         'frames': 66,\n",
       "         'madhubala': 9,\n",
       "         'liqueur': 1,\n",
       "         'afer': 2,\n",
       "         'cus': 3,\n",
       "         'factions': 10,\n",
       "         'synthesis': 11,\n",
       "         'shirdi': 1,\n",
       "         'blackish': 2,\n",
       "         'giraudeau': 1,\n",
       "         'amin': 16,\n",
       "         'hindi': 59,\n",
       "         'bending': 20,\n",
       "         'fogies': 2,\n",
       "         'dicpario': 1,\n",
       "         'ploughs': 1,\n",
       "         'yeats': 1,\n",
       "         'kiosk': 2,\n",
       "         'margot': 8,\n",
       "         'vivisects': 1,\n",
       "         'holsters': 1,\n",
       "         'nicmart': 1,\n",
       "         'barbecue': 11,\n",
       "         'bleek': 6,\n",
       "         'handmade': 2,\n",
       "         'ppk': 1,\n",
       "         'penis': 38,\n",
       "         'obtaining': 16,\n",
       "         'likeness': 12,\n",
       "         'dahlink': 1,\n",
       "         'zest': 13,\n",
       "         'anotherand': 1,\n",
       "         'adeptness': 1,\n",
       "         'defensa': 1,\n",
       "         'pagal': 1,\n",
       "         'blackadder': 25,\n",
       "         'encrusted': 2,\n",
       "         'crops': 12,\n",
       "         'bingley': 1,\n",
       "         'reb': 18,\n",
       "         'sweeet': 1,\n",
       "         'blogging': 2,\n",
       "         'tendo': 2,\n",
       "         'smoother': 6,\n",
       "         'haberdasheries': 1,\n",
       "         'obsessing': 2,\n",
       "         'misogynist': 6,\n",
       "         'instaneously': 1,\n",
       "         'concoct': 6,\n",
       "         'histoire': 2,\n",
       "         'glamouresque': 1,\n",
       "         'curvacious': 1,\n",
       "         'pardon': 24,\n",
       "         'spanjers': 5,\n",
       "         'behaviour': 75,\n",
       "         'rascal': 2,\n",
       "         'rutting': 1,\n",
       "         'stresses': 11,\n",
       "         'bruce': 393,\n",
       "         'ravenous': 14,\n",
       "         'infusion': 1,\n",
       "         'teletubbies': 6,\n",
       "         'vampira': 4,\n",
       "         'periodically': 19,\n",
       "         'fathering': 1,\n",
       "         'piovani': 6,\n",
       "         'yaarrrghhh': 1,\n",
       "         'usefull': 1,\n",
       "         'seon': 1,\n",
       "         'vile': 64,\n",
       "         'mouskouri': 1,\n",
       "         'sting': 25,\n",
       "         'hoydenish': 1,\n",
       "         'reasons': 596,\n",
       "         'necheyev': 1,\n",
       "         'underact': 2,\n",
       "         'guyana': 4,\n",
       "         'fluffy': 29,\n",
       "         'jal': 2,\n",
       "         'dramabaazi': 1,\n",
       "         'mutch': 3,\n",
       "         'successfullaughter': 1,\n",
       "         'touchy': 14,\n",
       "         'bettiefile': 1,\n",
       "         'fect': 1,\n",
       "         'escapes': 163,\n",
       "         'shaving': 19,\n",
       "         'vacillate': 1,\n",
       "         'chandu': 11,\n",
       "         'erin': 10,\n",
       "         'adorable': 101,\n",
       "         'holdup': 2,\n",
       "         'reanimates': 2,\n",
       "         'loosest': 6,\n",
       "         'jacket': 62,\n",
       "         'market': 218,\n",
       "         'postcard': 13,\n",
       "         'overrules': 1,\n",
       "         'keepers': 4,\n",
       "         'sued': 11,\n",
       "         'parachute': 9,\n",
       "         'echoes': 39,\n",
       "         'ensured': 6,\n",
       "         'elaborate': 118,\n",
       "         'renounces': 2,\n",
       "         'claudel': 1,\n",
       "         'freely': 30,\n",
       "         'sherawali': 1,\n",
       "         'aren': 886,\n",
       "         'atmosphere': 735,\n",
       "         'absurder': 2,\n",
       "         'ramu': 10,\n",
       "         'indulge': 31,\n",
       "         'pu': 7,\n",
       "         'roughness': 1,\n",
       "         'repute': 4,\n",
       "         'alderson': 1,\n",
       "         'lyricist': 4,\n",
       "         'hollering': 4,\n",
       "         'designers': 14,\n",
       "         'stanislav': 1,\n",
       "         'peavey': 2,\n",
       "         'magnoli': 1,\n",
       "         'tsunami': 10,\n",
       "         'rzone': 2,\n",
       "         'wwwaaaaayyyyy': 1,\n",
       "         'bintang': 1,\n",
       "         'samoan': 6,\n",
       "         'evenly': 11,\n",
       "         'bajillion': 1,\n",
       "         'bowden': 9,\n",
       "         'chod': 1,\n",
       "         'tajiri': 1,\n",
       "         'gatherers': 1,\n",
       "         'chancy': 1,\n",
       "         'ongoing': 37,\n",
       "         'corps': 6,\n",
       "         'hangings': 2,\n",
       "         'useless': 128,\n",
       "         'voila': 3,\n",
       "         'aleister': 2,\n",
       "         'rounds': 49,\n",
       "         'subculture': 7,\n",
       "         'defininitive': 1,\n",
       "         'directives': 2,\n",
       "         'korea': 55,\n",
       "         'camcorders': 4,\n",
       "         'greengrass': 21,\n",
       "         'kells': 48,\n",
       "         'gunns': 2,\n",
       "         'alanis': 3,\n",
       "         'michiko': 1,\n",
       "         'christ': 182,\n",
       "         'traci': 14,\n",
       "         'seamen': 2,\n",
       "         'dogtown': 3,\n",
       "         'linesmen': 2,\n",
       "         'undead': 64,\n",
       "         'nigga': 1,\n",
       "         'skinflint': 1,\n",
       "         'receipt': 4,\n",
       "         'atop': 28,\n",
       "         'vaude': 1,\n",
       "         'wiki': 6,\n",
       "         'barbarian': 36,\n",
       "         'cocker': 4,\n",
       "         'swiss': 40,\n",
       "         'rapp': 8,\n",
       "         'boomer': 10,\n",
       "         'scuffed': 1,\n",
       "         'ifan': 1,\n",
       "         'transformations': 22,\n",
       "         'cymbal': 2,\n",
       "         'ashtray': 1,\n",
       "         'mug': 18,\n",
       "         'confessor': 1,\n",
       "         'hinckley': 2,\n",
       "         'revolutionary': 103,\n",
       "         'hippest': 1,\n",
       "         'accuser': 3,\n",
       "         'shoves': 12,\n",
       "         'missive': 1,\n",
       "         'applies': 48,\n",
       "         'worth': 2278,\n",
       "         'aborigines': 20,\n",
       "         'enticed': 2,\n",
       "         'whiteboy': 1,\n",
       "         'quad': 2,\n",
       "         'talosian': 1,\n",
       "         'dominos': 1,\n",
       "         'naudets': 4,\n",
       "         'monograms': 2,\n",
       "         'competitive': 29,\n",
       "         'oppositions': 2,\n",
       "         'daredevil': 13,\n",
       "         'ravages': 6,\n",
       "         'sanguisga': 1,\n",
       "         'chianese': 6,\n",
       "         'carving': 13,\n",
       "         'tranquillo': 1,\n",
       "         'deco': 16,\n",
       "         'major': 927,\n",
       "         'scheduling': 7,\n",
       "         'despondency': 1,\n",
       "         'forensics': 10,\n",
       "         'bradbury': 16,\n",
       "         'classmate': 13,\n",
       "         'volo': 2,\n",
       "         'tramonti': 1,\n",
       "         'restless': 34,\n",
       "         'naffly': 1,\n",
       "         'trampled': 10,\n",
       "         'readying': 2,\n",
       "         'nominated': 222,\n",
       "         'devotes': 4,\n",
       "         'ideals': 44,\n",
       "         'grantness': 1,\n",
       "         'invisible': 200,\n",
       "         'condone': 6,\n",
       "         'nonsense': 287,\n",
       "         'welcome': 214,\n",
       "         'dezel': 1,\n",
       "         'achieves': 54,\n",
       "         'cinmas': 1,\n",
       "         'such': 5134,\n",
       "         'balzac': 6,\n",
       "         'yakima': 6,\n",
       "         'unrestrained': 10,\n",
       "         'ryne': 1,\n",
       "         'offbeat': 59,\n",
       "         'honerable': 1,\n",
       "         'contributor': 5,\n",
       "         'banquo': 1,\n",
       "         'agostino': 1,\n",
       "         'eliminating': 16,\n",
       "         'galleghar': 2,\n",
       "         'visibile': 1,\n",
       "         'unfurls': 1,\n",
       "         'shortest': 8,\n",
       "         'warfare': 29,\n",
       "         'turhan': 5,\n",
       "         'adelin': 1,\n",
       "         'fanfaberies': 1,\n",
       "         'wiles': 3,\n",
       "         'roared': 4,\n",
       "         'hier': 1,\n",
       "         'dietrickson': 2,\n",
       "         'liner': 43,\n",
       "         'peritonitis': 1,\n",
       "         'killling': 1,\n",
       "         'skinny': 54,\n",
       "         'flickerino': 1,\n",
       "         'sours': 1,\n",
       "         'out': 17113,\n",
       "         'punctuality': 1,\n",
       "         'removed': 108,\n",
       "         'killshot': 1,\n",
       "         'deville': 3,\n",
       "         'banality': 22,\n",
       "         'ordeals': 4,\n",
       "         'dreamers': 4,\n",
       "         'zonfeld': 1,\n",
       "         'shimono': 2,\n",
       "         'failings': 18,\n",
       "         'cor': 1,\n",
       "         'taped': 56,\n",
       "         'practicality': 7,\n",
       "         'dodges': 6,\n",
       "         'archetypes': 10,\n",
       "         'terrifyingly': 13,\n",
       "         'reborn': 7,\n",
       "         'beardy': 1,\n",
       "         'mishin': 1,\n",
       "         'entered': 64,\n",
       "         'puede': 1,\n",
       "         'skillful': 22,\n",
       "         'troubled': 145,\n",
       "         'ah': 119,\n",
       "         'fantastic': 797,\n",
       "         'aramaic': 3,\n",
       "         'essentials': 6,\n",
       "         'stricken': 39,\n",
       "         'personage': 4,\n",
       "         'surveilling': 1,\n",
       "         'miscegenation': 1,\n",
       "         'darthvader': 1,\n",
       "         'xvi': 2,\n",
       "         'preplanning': 1,\n",
       "         'pubertal': 1,\n",
       "         'sickness': 44,\n",
       "         'cringeworthy': 10,\n",
       "         'kisna': 1,\n",
       "         'delusional': 21,\n",
       "         'suriani': 1,\n",
       "         'bonesetter': 3,\n",
       "         'bathtubs': 1,\n",
       "         'maladroit': 3,\n",
       "         'legalize': 2,\n",
       "         'worshiping': 6,\n",
       "         'espanol': 1,\n",
       "         'capture': 287,\n",
       "         'perplexing': 19,\n",
       "         'pochath': 3,\n",
       "         'gauze': 2,\n",
       "         'takaya': 1,\n",
       "         'reject': 43,\n",
       "         'wishi': 1,\n",
       "         'harel': 6,\n",
       "         'transcend': 23,\n",
       "         'batteries': 8,\n",
       "         'pastry': 1,\n",
       "         'polarization': 3,\n",
       "         'dudleys': 1,\n",
       "         'storybooks': 1,\n",
       "         'orient': 6,\n",
       "         'krank': 1,\n",
       "         'disputing': 1,\n",
       "         'sisabled': 1,\n",
       "         'shifting': 37,\n",
       "         'petites': 1,\n",
       "         'sommers': 1,\n",
       "         'disobedient': 3,\n",
       "         'pitting': 10,\n",
       "         'unerotic': 7,\n",
       "         'ghostbusters': 8,\n",
       "         'oom': 3,\n",
       "         'damiano': 1,\n",
       "         'frighteningly': 15,\n",
       "         'sng': 1,\n",
       "         'painkiller': 1,\n",
       "         'stemmin': 1,\n",
       "         'blaznee': 1,\n",
       "         'neighbour': 21,\n",
       "         'desis': 1,\n",
       "         'domergue': 25,\n",
       "         'graduation': 23,\n",
       "         'fever': 116,\n",
       "         'tetsuoooo': 1,\n",
       "         'develop': 252,\n",
       "         'ishmael': 4,\n",
       "         'poisen': 1,\n",
       "         'validates': 5,\n",
       "         'fabio': 8,\n",
       "         'phyllis': 32,\n",
       "         'alight': 7,\n",
       "         'lackies': 1,\n",
       "         'castro': 45,\n",
       "         'hotty': 1,\n",
       "         'cirus': 1,\n",
       "         'hugging': 19,\n",
       "         'catchphrases': 9,\n",
       "         'rodolfo': 3,\n",
       "         'lapaglia': 1,\n",
       "         'stressing': 2,\n",
       "         'intuitor': 2,\n",
       "         'inhabited': 35,\n",
       "         'uncertain': 40,\n",
       "         'hinders': 2,\n",
       "         'commence': 4,\n",
       "         'probarly': 1,\n",
       "         'cabby': 2,\n",
       "         'ono': 3,\n",
       "         'mercurio': 5,\n",
       "         'sickens': 6,\n",
       "         'lyric': 20,\n",
       "         'deborah': 38,\n",
       "         'forklift': 1,\n",
       "         'publication': 11,\n",
       "         'tweak': 5,\n",
       "         'stipulation': 1,\n",
       "         'idyllically': 1,\n",
       "         'overfed': 1,\n",
       "         'aboard': 37,\n",
       "         'genies': 7,\n",
       "         'councellor': 3,\n",
       "         'patrolled': 1,\n",
       "         'hurrah': 3,\n",
       "         'clarity': 45,\n",
       "         'squirt': 4,\n",
       "         'smg': 2,\n",
       "         'lugia': 9,\n",
       "         'riffen': 2,\n",
       "         'counterpoints': 2,\n",
       "         'luxury': 39,\n",
       "         'baitz': 1,\n",
       "         'fuhgeddaboudit': 1,\n",
       "         'astin': 8,\n",
       "         'lacerated': 1,\n",
       "         'cairns': 2,\n",
       "         'showthe': 1,\n",
       "         'northt': 1,\n",
       "         'madolyn': 3,\n",
       "         'kerosine': 1,\n",
       "         'screenwrtier': 1,\n",
       "         'actorsactresses': 1,\n",
       "         'noisily': 1,\n",
       "         'brocksmith': 1,\n",
       "         'trespassing': 4,\n",
       "         'drifters': 6,\n",
       "         'bradycardia': 1,\n",
       "         'tantalised': 2,\n",
       "         'fangoria': 10,\n",
       "         'vapid': 43,\n",
       "         'remakes': 77,\n",
       "         'lavvies': 1,\n",
       "         'romances': 53,\n",
       "         'heroin': 37,\n",
       "         'tames': 1,\n",
       "         'deluca': 1,\n",
       "         'solipsism': 2,\n",
       "         'movies': 7666,\n",
       "         'foran': 10,\n",
       "         'packy': 1,\n",
       "         'englishmen': 4,\n",
       "         'mathieu': 67,\n",
       "         'extravagance': 4,\n",
       "         'dwan': 2,\n",
       "         'smooths': 1,\n",
       "         'copy': 576,\n",
       "         'scowl': 8,\n",
       "         'unrecycled': 1,\n",
       "         'data': 42,\n",
       "         'coherrent': 1,\n",
       "         'declined': 18,\n",
       "         'someplace': 17,\n",
       "         'elope': 2,\n",
       "         'scythe': 5,\n",
       "         'kombat': 4,\n",
       "         'chorines': 3,\n",
       "         'outlets': 7,\n",
       "         'unwanted': 23,\n",
       "         'irak': 5,\n",
       "         'settled': 54,\n",
       "         'enamoured': 4,\n",
       "         'melanie': 15,\n",
       "         'prussian': 1,\n",
       "         'greyfriars': 1,\n",
       "         'waterboy': 1,\n",
       "         'captions': 9,\n",
       "         'lovin': 9,\n",
       "         'handycams': 1,\n",
       "         'loire': 2,\n",
       "         'goriness': 1,\n",
       "         'paramedic': 2,\n",
       "         'olympus': 1,\n",
       "         'nyfd': 2,\n",
       "         'rithmetic': 1,\n",
       "         'decorated': 24,\n",
       "         'scams': 7,\n",
       "         'cornyness': 1,\n",
       "         'proscriptions': 1,\n",
       "         'longlegs': 1,\n",
       "         'perils': 19,\n",
       "         'littered': 9,\n",
       "         'pinup': 11,\n",
       "         'miseries': 5,\n",
       "         'author': 274,\n",
       "         'teeter': 1,\n",
       "         'shooked': 1,\n",
       "         'shiploads': 1,\n",
       "         'creme': 6,\n",
       "         'chans': 6,\n",
       "         'avoids': 43,\n",
       "         'separately': 22,\n",
       "         'reap': 5,\n",
       "         'wierder': 1,\n",
       "         'standish': 2,\n",
       "         'spheerhead': 1,\n",
       "         'compositor': 2,\n",
       "         'unsophisticated': 18,\n",
       "         'sibiriada': 1,\n",
       "         'postwar': 19,\n",
       "         'atavistic': 1,\n",
       "         'dynasty': 16,\n",
       "         'kinski': 44,\n",
       "         'gobi': 1,\n",
       "         'shogo': 6,\n",
       "         'restaraunt': 3,\n",
       "         'pickett': 1,\n",
       "         'jalees': 1,\n",
       "         'impalements': 2,\n",
       "         'supped': 1,\n",
       "         'toughen': 1,\n",
       "         'exceeding': 2,\n",
       "         'geronimi': 1,\n",
       "         'gideon': 14,\n",
       "         'charterers': 1,\n",
       "         'pilcher': 2,\n",
       "         'snaking': 1,\n",
       "         'location': 337,\n",
       "         'whetted': 3,\n",
       "         'offensively': 10,\n",
       "         'exacts': 3,\n",
       "         'irresponsible': 35,\n",
       "         'sharukh': 1,\n",
       "         'polynesia': 6,\n",
       "         'teeming': 4,\n",
       "         'ecosystems': 3,\n",
       "         'milwall': 2,\n",
       "         'unjustifiably': 1,\n",
       "         'rasta': 3,\n",
       "         'craptitude': 1,\n",
       "         'controversial': 152,\n",
       "         'abusers': 2,\n",
       "         'teeenage': 1,\n",
       "         'disconnects': 1,\n",
       "         'exupry': 1,\n",
       "         'inamdar': 2,\n",
       "         'cought': 1,\n",
       "         'solos': 8,\n",
       "         'riding': 155,\n",
       "         'abunch': 1,\n",
       "         'straggle': 1,\n",
       "         'sharmila': 1,\n",
       "         'krypyonite': 1,\n",
       "         'nashville': 11,\n",
       "         'oswald': 14,\n",
       "         'kilmore': 1,\n",
       "         'reconnoitering': 1,\n",
       "         'overdose': 16,\n",
       "         'tristesse': 4,\n",
       "         'yanos': 5,\n",
       "         'decry': 3,\n",
       "         'tobias': 18,\n",
       "         'eraser': 5,\n",
       "         'monstroid': 1,\n",
       "         'persuading': 6,\n",
       "         'skinheads': 9,\n",
       "         'exasperation': 7,\n",
       "         'entering': 60,\n",
       "         'hotch': 3,\n",
       "         'bret': 22,\n",
       "         'dorf': 6,\n",
       "         'idk': 4,\n",
       "         'pediatrician': 1,\n",
       "         'farmhouses': 1,\n",
       "         'ilenia': 1,\n",
       "         'orbitting': 1,\n",
       "         'casted': 40,\n",
       "         'considerable': 97,\n",
       "         'roughhousing': 2,\n",
       "         'springer': 75,\n",
       "         'tells': 881,\n",
       "         'brutal': 303,\n",
       "         'reportedly': 37,\n",
       "         'whistleblowing': 1,\n",
       "         'moviesuntil': 1,\n",
       "         'weekends': 9,\n",
       "         'synths': 2,\n",
       "         'hr': 12,\n",
       "         'ties': 104,\n",
       "         'nigh': 15,\n",
       "         'overestimate': 1,\n",
       "         'nothan': 1,\n",
       "         'sophmoric': 3,\n",
       "         'evita': 3,\n",
       "         'raksha': 2,\n",
       "         'assumptions': 25,\n",
       "         'lucian': 5,\n",
       "         'unconventional': 44,\n",
       "         'downers': 1,\n",
       "         'vp': 5,\n",
       "         'improvisationally': 1,\n",
       "         'unmysterious': 1,\n",
       "         'naive': 218,\n",
       "         'oneida': 1,\n",
       "         'trounced': 2,\n",
       "         'entropy': 3,\n",
       "         'torque': 3,\n",
       "         'eaters': 21,\n",
       "         'frightfully': 8,\n",
       "         'licked': 1,\n",
       "         'rigorously': 3,\n",
       "         'methodical': 10,\n",
       "         'cross': 325,\n",
       "         'stoner': 17,\n",
       "         'geico': 11,\n",
       "         'immatured': 1,\n",
       "         'horrify': 1,\n",
       "         'vicki': 22,\n",
       "         'primer': 9,\n",
       "         'driver': 195,\n",
       "         'inspirations': 2,\n",
       "         'lethargic': 22,\n",
       "         'obcession': 4,\n",
       "         'ringed': 1,\n",
       "         'lovely': 424,\n",
       "         'trouser': 1,\n",
       "         'maturing': 2,\n",
       "         ...})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "total_counts = Counter()\n",
    "for _, row in reviews.iterrows():\n",
    "    total_counts.update(row[0].split(' '))\n",
    "print(\"Total words in data set: \", len(total_counts))\n",
    "total_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the first 10000 most frequent words. As Andrew noted, most of the words in the vocabulary are rarely used so they will have little effect on our predictions. Below, we'll sort `vocab` by the count value and keep the 10000 most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'the', '.', 'and', 'a', 'of', 'to', 'is', 'br', 'it', 'in', 'i', 'this', 'that', 's', 'was', 'as', 'for', 'with', 'movie', 'but', 'film', 'you', 'on', 't', 'not', 'he', 'are', 'his', 'have', 'be', 'one', 'all', 'at', 'they', 'by', 'an', 'who', 'so', 'from', 'like', 'there', 'her', 'or', 'just', 'about', 'out', 'if', 'has', 'what', 'some', 'good', 'can', 'more', 'she', 'when', 'very', 'up', 'time', 'no']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(total_counts, key=total_counts.get, reverse=True)[:10000]\n",
    "print(vocab[:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the last word in our vocabulary? We can use this to judge if 10000 is too few. If the last word is pretty common, we probably need to keep more words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registered :  30\n"
     ]
    }
   ],
   "source": [
    "print(vocab[-1], ': ', total_counts[vocab[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last word in our vocabulary shows up in 30 reviews out of 25000. I think it's fair to say this is a tiny proportion of reviews. We are probably fine with this number of words.\n",
    "\n",
    "**Note:** When you run, you may see a different word from the one shown above, but it will also have the value `30`. That's because there are many words tied for that number of counts, and the `Counter` class does not guarantee which one will be returned in the case of a tie.\n",
    "\n",
    "Now for each review in the data, we'll make a word vector. First we need to make a mapping of word to index, pretty easy to do with a dictionary comprehension.\n",
    "\n",
    "> **Exercise:** Create a dictionary called `word2idx` that maps each word in the vocabulary to an index. The first word in `vocab` has index `0`, the second word has index `1`, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'entitled': 5584,\n",
       " 'locker': 9633,\n",
       " 'iturbi': 6717,\n",
       " 'nutty': 9105,\n",
       " 'ones': 646,\n",
       " 'referred': 5381,\n",
       " 'shadowy': 9607,\n",
       " 'cruelty': 5548,\n",
       " 'could': 98,\n",
       " 'grow': 2262,\n",
       " 'lugosi': 2514,\n",
       " 'models': 4103,\n",
       " 'midler': 8205,\n",
       " 'distracted': 7054,\n",
       " 'wolverine': 9398,\n",
       " 'asking': 2229,\n",
       " 'soon': 505,\n",
       " 'colonial': 9547,\n",
       " 'recognition': 4633,\n",
       " 'fleet': 6995,\n",
       " 'channels': 4811,\n",
       " 'never': 115,\n",
       " 'effort': 766,\n",
       " 'average': 833,\n",
       " 'lyrical': 9300,\n",
       " 'take': 192,\n",
       " 'quit': 4952,\n",
       " 'wrong': 351,\n",
       " 'considers': 7743,\n",
       " 'athletic': 8591,\n",
       " 'mining': 9434,\n",
       " 'jon': 2598,\n",
       " 'remotely': 2570,\n",
       " 'mitchell': 3530,\n",
       " 'letdown': 7719,\n",
       " 'relationship': 634,\n",
       " 'admired': 6664,\n",
       " 'tail': 5498,\n",
       " 'proving': 5889,\n",
       " 'statement': 2557,\n",
       " 'trio': 3885,\n",
       " 'actors': 157,\n",
       " 'parade': 5149,\n",
       " 'randy': 4748,\n",
       " 'retains': 9894,\n",
       " 'ourselves': 3112,\n",
       " 'golf': 8677,\n",
       " 'wife': 312,\n",
       " 'brazilian': 7974,\n",
       " 'ford': 1732,\n",
       " 'stalking': 6223,\n",
       " 'icon': 4896,\n",
       " 'candidate': 6036,\n",
       " 'bela': 4480,\n",
       " 'higher': 1813,\n",
       " 'officer': 1857,\n",
       " 'ruthless': 4226,\n",
       " 'ego': 3463,\n",
       " 'exciting': 1105,\n",
       " 'survivors': 4220,\n",
       " 'resembling': 7212,\n",
       " 'sexist': 7723,\n",
       " 'though': 151,\n",
       " 'number': 601,\n",
       " 'madison': 7521,\n",
       " 'feminist': 4902,\n",
       " 'justification': 8447,\n",
       " 'jessica': 2813,\n",
       " 'magnificent': 1982,\n",
       " 'whilst': 1847,\n",
       " 'horny': 6579,\n",
       " 'leia': 9166,\n",
       " 'farewell': 8983,\n",
       " 'pbs': 9904,\n",
       " 'filmography': 7622,\n",
       " 'footage': 910,\n",
       " 'gielgud': 6686,\n",
       " 'gem': 1502,\n",
       " 'louise': 4641,\n",
       " 'confront': 6278,\n",
       " 'anna': 2046,\n",
       " 'dealt': 3315,\n",
       " 'juan': 6894,\n",
       " 'neglected': 6933,\n",
       " 'dvds': 5815,\n",
       " 'meat': 3489,\n",
       " 'motive': 6156,\n",
       " 'ernie': 7477,\n",
       " 'guard': 2848,\n",
       " 'prop': 7710,\n",
       " 'cells': 7747,\n",
       " 'labeled': 8090,\n",
       " 'empathy': 4914,\n",
       " 'suddenly': 1062,\n",
       " 'fashioned': 3291,\n",
       " 'core': 2001,\n",
       " 'vera': 6936,\n",
       " 'breakthrough': 8948,\n",
       " 'souls': 3626,\n",
       " 'boll': 3182,\n",
       " 'nifty': 8593,\n",
       " 'physical': 1717,\n",
       " 'lorre': 8755,\n",
       " 'italy': 3052,\n",
       " 'net': 5526,\n",
       " 'cocktail': 9180,\n",
       " 'namely': 4469,\n",
       " 'tunnel': 5728,\n",
       " 'baked': 8133,\n",
       " 'depression': 3454,\n",
       " 'start': 374,\n",
       " 'sickening': 6703,\n",
       " 'criminal': 1635,\n",
       " 'necessity': 7164,\n",
       " 'frye': 9892,\n",
       " 'marilyn': 6785,\n",
       " 'advances': 8210,\n",
       " 'dealing': 1934,\n",
       " 'dixon': 4499,\n",
       " 'karloff': 3128,\n",
       " 'option': 5366,\n",
       " 'rosenstrasse': 8313,\n",
       " 'seek': 2701,\n",
       " 'archive': 9278,\n",
       " 'cuban': 6753,\n",
       " 'rotten': 4431,\n",
       " 'iii': 3345,\n",
       " 'episodic': 9654,\n",
       " 'mason': 6002,\n",
       " 'noteworthy': 6937,\n",
       " 'visits': 4665,\n",
       " 'cons': 5991,\n",
       " 'prefers': 8706,\n",
       " 'rule': 2601,\n",
       " 'coarse': 9690,\n",
       " 'so': 38,\n",
       " 'laboratory': 7280,\n",
       " 'fifties': 5556,\n",
       " 'reviews': 838,\n",
       " 'raunchy': 7729,\n",
       " 'addresses': 9827,\n",
       " 'interests': 5009,\n",
       " 'thousands': 3044,\n",
       " 'fame': 2217,\n",
       " 'thinks': 1272,\n",
       " 'sandy': 8069,\n",
       " 'occasional': 2518,\n",
       " 'entirely': 1073,\n",
       " 'networks': 7839,\n",
       " 'expose': 6495,\n",
       " 'trivial': 7557,\n",
       " 'ham': 4903,\n",
       " 'macabre': 6170,\n",
       " 'courtesy': 7421,\n",
       " 'existent': 2951,\n",
       " 'crashing': 6572,\n",
       " 'lasted': 4288,\n",
       " 'develop': 2039,\n",
       " 'hopefully': 2333,\n",
       " 'russia': 5118,\n",
       " 'eric': 1942,\n",
       " 'dream': 894,\n",
       " 'nemesis': 5347,\n",
       " 'chris': 1307,\n",
       " 'melinda': 8570,\n",
       " 'par': 2245,\n",
       " 'hawke': 5119,\n",
       " 'collecting': 9172,\n",
       " 'on': 23,\n",
       " 'gertrude': 9840,\n",
       " 'dick': 1784,\n",
       " 'ace': 5730,\n",
       " 'hopeless': 5017,\n",
       " 'string': 3568,\n",
       " 'able': 494,\n",
       " 'efforts': 2032,\n",
       " 'salman': 6023,\n",
       " 'trap': 3572,\n",
       " 'hole': 2916,\n",
       " 'hour': 523,\n",
       " 'lust': 3992,\n",
       " 'comedy': 208,\n",
       " 'sparse': 9415,\n",
       " 'cousins': 8928,\n",
       " 'approximately': 9242,\n",
       " 'murdered': 1989,\n",
       " 'hark': 8881,\n",
       " 'getting': 391,\n",
       " 'energetic': 6258,\n",
       " 'parks': 8279,\n",
       " 'prostitute': 3948,\n",
       " 'consciousness': 6736,\n",
       " 'bing': 8321,\n",
       " 'improbable': 6288,\n",
       " 'unfamiliar': 7644,\n",
       " 'walks': 2338,\n",
       " 'duel': 6718,\n",
       " 'greed': 4788,\n",
       " 'pad': 6742,\n",
       " 'subdued': 8525,\n",
       " 'top': 345,\n",
       " 'charlie': 1262,\n",
       " 'images': 1197,\n",
       " 'rizzo': 8790,\n",
       " 'contributes': 8592,\n",
       " 'hmmm': 7088,\n",
       " 'joe': 866,\n",
       " 'humorous': 1964,\n",
       " 'sword': 2504,\n",
       " 'rourke': 7376,\n",
       " 'losing': 2286,\n",
       " 'syndrome': 6309,\n",
       " 'bills': 8617,\n",
       " 'insanity': 5941,\n",
       " 'furniture': 6546,\n",
       " 'screen': 262,\n",
       " 'enthusiasm': 4800,\n",
       " 'callahan': 9032,\n",
       " 'nobody': 1238,\n",
       " 'michel': 9321,\n",
       " 'premiere': 5153,\n",
       " 'chong': 6737,\n",
       " 'commercial': 2138,\n",
       " 'lommel': 8906,\n",
       " 'faults': 4361,\n",
       " 'characterizations': 7324,\n",
       " 'bleed': 7222,\n",
       " 'damage': 4001,\n",
       " 'slam': 8031,\n",
       " 'davis': 1527,\n",
       " 'impressions': 8325,\n",
       " 'projected': 7501,\n",
       " 'stretched': 4930,\n",
       " 'hunted': 7745,\n",
       " 'halloween': 2100,\n",
       " 'bacon': 5232,\n",
       " 'cry': 1384,\n",
       " 'tragic': 1552,\n",
       " 'palance': 5129,\n",
       " 'ghosts': 2671,\n",
       " 'consider': 1107,\n",
       " 'secrets': 3870,\n",
       " 'fuzzy': 6896,\n",
       " 'lists': 8510,\n",
       " 'icy': 8541,\n",
       " 'directing': 918,\n",
       " 'shameless': 7645,\n",
       " 'cartoon': 1051,\n",
       " 'led': 1619,\n",
       " 'flair': 5163,\n",
       " 'mockery': 8908,\n",
       " 'castro': 7577,\n",
       " 'principal': 4136,\n",
       " 'matthau': 2997,\n",
       " 'carlos': 7418,\n",
       " 'bull': 4291,\n",
       " 'conspiracy': 3514,\n",
       " 'lends': 6965,\n",
       " 'rub': 9610,\n",
       " 'villa': 8409,\n",
       " 'insights': 6044,\n",
       " 'exceptional': 3122,\n",
       " 'impending': 8005,\n",
       " 'available': 1415,\n",
       " 'flee': 9508,\n",
       " 'worse': 430,\n",
       " 'jolie': 6617,\n",
       " 'paragraph': 8064,\n",
       " 'uwe': 4217,\n",
       " 'overacting': 4772,\n",
       " 'reese': 8078,\n",
       " 'brit': 7947,\n",
       " 'gypsy': 7730,\n",
       " 'lesbian': 2408,\n",
       " 'blown': 2641,\n",
       " 'freak': 3749,\n",
       " 'indeed': 831,\n",
       " 'brenda': 4886,\n",
       " 'dynamics': 6794,\n",
       " 'mo': 8811,\n",
       " 'boost': 8761,\n",
       " 'memory': 1723,\n",
       " 'zombies': 1099,\n",
       " 'portman': 8877,\n",
       " 'lara': 7681,\n",
       " 'appealing': 2253,\n",
       " 'brain': 1189,\n",
       " 'revelations': 9274,\n",
       " 'crashed': 8004,\n",
       " 'abundance': 7711,\n",
       " 'principals': 6426,\n",
       " 'bombed': 8336,\n",
       " 'gloria': 6938,\n",
       " 'performances': 352,\n",
       " 'ups': 1951,\n",
       " 'officially': 8265,\n",
       " 'fuller': 4931,\n",
       " 'suspicion': 7019,\n",
       " 'jacques': 6635,\n",
       " 'paramount': 5195,\n",
       " 'driven': 2136,\n",
       " 'static': 5780,\n",
       " 'continent': 8626,\n",
       " 'graveyard': 6685,\n",
       " 'marital': 9509,\n",
       " 'intelligently': 8531,\n",
       " 'additional': 5393,\n",
       " 'incidental': 7961,\n",
       " 'track': 1383,\n",
       " 'gackt': 7248,\n",
       " 'misunderstood': 6982,\n",
       " 'term': 2858,\n",
       " 'fast': 689,\n",
       " 'cooper': 2866,\n",
       " 'aime': 7439,\n",
       " 'rampage': 6005,\n",
       " 'remains': 1265,\n",
       " 'readers': 6362,\n",
       " 'psychotic': 3667,\n",
       " 'nearly': 743,\n",
       " 'masses': 4932,\n",
       " 'kiddie': 9000,\n",
       " 'touch': 1193,\n",
       " 'disgrace': 5995,\n",
       " 'gone': 810,\n",
       " 'nell': 9730,\n",
       " 'russians': 8428,\n",
       " 'miserably': 3579,\n",
       " 'transparent': 7668,\n",
       " 'townsend': 9538,\n",
       " 'norman': 3501,\n",
       " 'dictator': 7899,\n",
       " 'whose': 616,\n",
       " 'btk': 9413,\n",
       " 'twenties': 9893,\n",
       " 'grendel': 7298,\n",
       " 'achievements': 7588,\n",
       " 'psychedelic': 7367,\n",
       " 'footsteps': 9153,\n",
       " 'superhero': 3693,\n",
       " 'hill': 2109,\n",
       " 'following': 1025,\n",
       " 'saints': 8117,\n",
       " 'chest': 4539,\n",
       " 'grey': 2985,\n",
       " 'shady': 8708,\n",
       " 'score': 590,\n",
       " 'dime': 9143,\n",
       " 'angelina': 7345,\n",
       " 'sammy': 8093,\n",
       " 'capacity': 7234,\n",
       " 'stuffed': 7580,\n",
       " 'thread': 5470,\n",
       " 'fabulous': 2713,\n",
       " 'kubrick': 3434,\n",
       " 'scale': 2372,\n",
       " 'newcomer': 6754,\n",
       " 'circumstances': 2304,\n",
       " 'manipulative': 4720,\n",
       " 'yours': 6350,\n",
       " 'stopped': 2208,\n",
       " 'swallow': 6138,\n",
       " 'by': 35,\n",
       " 'orlando': 8381,\n",
       " 'duvall': 5280,\n",
       " 'moron': 6452,\n",
       " 'marry': 2251,\n",
       " 'rodriguez': 7364,\n",
       " 'vulnerable': 4593,\n",
       " 'jumbo': 9715,\n",
       " 'doris': 8738,\n",
       " 'innocent': 1327,\n",
       " 'liar': 8512,\n",
       " 'admission': 7691,\n",
       " 'rico': 9117,\n",
       " 'connery': 4462,\n",
       " 'requisite': 9436,\n",
       " 'afterward': 6610,\n",
       " 'cheerful': 7657,\n",
       " 'bud': 4933,\n",
       " 'zombie': 819,\n",
       " 'trees': 4094,\n",
       " 'prototype': 9539,\n",
       " 'must': 207,\n",
       " 'concludes': 9051,\n",
       " 'affecting': 7802,\n",
       " 'magazines': 8057,\n",
       " 'vacation': 2970,\n",
       " 'vile': 5963,\n",
       " 'advise': 4608,\n",
       " 'immediately': 1214,\n",
       " 'moments': 382,\n",
       " 'embrace': 6457,\n",
       " 'voting': 9530,\n",
       " 'humor': 477,\n",
       " 'rid': 3719,\n",
       " 'raping': 9822,\n",
       " 'peckinpah': 7964,\n",
       " 'pixar': 5781,\n",
       " 'cheese': 2983,\n",
       " 'unaware': 4934,\n",
       " 'platoon': 9178,\n",
       " '.': 2,\n",
       " 'rice': 7002,\n",
       " 'audience': 301,\n",
       " 'trademark': 5042,\n",
       " 'pulse': 9482,\n",
       " 'peterson': 8730,\n",
       " 'air': 923,\n",
       " 'aviv': 9796,\n",
       " 'exhibit': 9573,\n",
       " 'corporation': 6057,\n",
       " 'benoit': 8970,\n",
       " 'as': 16,\n",
       " 'culminating': 9697,\n",
       " 'casually': 9279,\n",
       " 'sinking': 6235,\n",
       " 'reflect': 4565,\n",
       " 'prove': 1956,\n",
       " 'notion': 4111,\n",
       " 'wig': 5691,\n",
       " 'memorable': 888,\n",
       " 'process': 1750,\n",
       " 'quantum': 6496,\n",
       " 'military': 1213,\n",
       " 'atmospheric': 3120,\n",
       " 'counts': 5367,\n",
       " 'partners': 5646,\n",
       " 'hapless': 5655,\n",
       " 'rightly': 7473,\n",
       " 'lily': 3399,\n",
       " 'stereotyped': 7436,\n",
       " 'attraction': 3213,\n",
       " 'complaint': 3285,\n",
       " 'position': 2704,\n",
       " 'dedication': 8618,\n",
       " 'caine': 2418,\n",
       " 'gina': 5436,\n",
       " 'resume': 7200,\n",
       " 'ensues': 4715,\n",
       " 'barker': 7589,\n",
       " 'grandfather': 4323,\n",
       " 'chat': 8895,\n",
       " 'void': 6903,\n",
       " 'alter': 6697,\n",
       " 'zorro': 6407,\n",
       " 'dilemma': 6310,\n",
       " 'flight': 2724,\n",
       " 'horrible': 518,\n",
       " 'bunch': 745,\n",
       " 'normally': 1733,\n",
       " 'charges': 7624,\n",
       " 'segment': 2033,\n",
       " 'curiosity': 3573,\n",
       " 'sarne': 8723,\n",
       " 'lighter': 6201,\n",
       " 'foxx': 5168,\n",
       " 'bennett': 7244,\n",
       " 'bad': 77,\n",
       " 'tits': 7609,\n",
       " 'azaria': 9302,\n",
       " 'clunky': 7448,\n",
       " 'mask': 2273,\n",
       " 'combat': 3957,\n",
       " 'jackson': 1586,\n",
       " 'tries': 490,\n",
       " 'hoover': 8493,\n",
       " 'giallo': 3727,\n",
       " 'culkin': 8213,\n",
       " 'belong': 4823,\n",
       " 'akshay': 4201,\n",
       " 'bury': 9184,\n",
       " 'fred': 1739,\n",
       " 'customs': 9194,\n",
       " 'gang': 1310,\n",
       " 'korda': 8901,\n",
       " 'metropolis': 8950,\n",
       " 'perceived': 8954,\n",
       " 'orchestra': 7471,\n",
       " 'hogan': 8717,\n",
       " 'tenant': 5530,\n",
       " 'jimmy': 1898,\n",
       " 'inhabit': 8526,\n",
       " 'museum': 4400,\n",
       " 'wright': 7055,\n",
       " 'wes': 3660,\n",
       " 'dump': 6427,\n",
       " 'where': 119,\n",
       " 'up': 57,\n",
       " 'stories': 527,\n",
       " 'intellectually': 8565,\n",
       " 'weaves': 9812,\n",
       " 'gigantic': 7221,\n",
       " 'th': 814,\n",
       " 'barnes': 8083,\n",
       " 'el': 5353,\n",
       " 'submit': 9243,\n",
       " 'fears': 3526,\n",
       " 'awakens': 9791,\n",
       " 'dad': 1152,\n",
       " 'muppet': 5425,\n",
       " 'keitel': 8810,\n",
       " 'linear': 6122,\n",
       " 'existing': 7325,\n",
       " 'levels': 2165,\n",
       " 'sailors': 9013,\n",
       " 'spitting': 9001,\n",
       " 'sly': 7152,\n",
       " 'crawford': 4979,\n",
       " 'ability': 1232,\n",
       " 'adequately': 9104,\n",
       " 'cbc': 9141,\n",
       " 'shelley': 4432,\n",
       " 'fighting': 976,\n",
       " 'parallel': 4678,\n",
       " 'train': 1341,\n",
       " 'gravity': 8601,\n",
       " 'satisfy': 4749,\n",
       " 'regain': 9464,\n",
       " 'norton': 7888,\n",
       " 'topped': 9661,\n",
       " 'arrest': 6695,\n",
       " 'flew': 8533,\n",
       " 'unsatisfying': 6595,\n",
       " 'phenomenon': 5667,\n",
       " 'thunderbirds': 6087,\n",
       " 'buy': 796,\n",
       " 'foul': 3915,\n",
       " 'fancy': 3690,\n",
       " 'romantic': 713,\n",
       " 'thankful': 9422,\n",
       " 'elizabeth': 2746,\n",
       " 'solving': 9609,\n",
       " 'get': 76,\n",
       " 'legion': 8772,\n",
       " 'professionals': 6836,\n",
       " 'killing': 863,\n",
       " 'slap': 3634,\n",
       " 'selling': 3459,\n",
       " 'meek': 7883,\n",
       " 'uniform': 6280,\n",
       " 'mountain': 2498,\n",
       " 'doc': 3317,\n",
       " 'scientist': 1595,\n",
       " 'costs': 2176,\n",
       " 'gore': 582,\n",
       " 'causes': 2876,\n",
       " 'worm': 8217,\n",
       " 'scenario': 2650,\n",
       " 'brides': 7202,\n",
       " 'rented': 1591,\n",
       " 'grady': 8545,\n",
       " 'doom': 4645,\n",
       " 'sassy': 5491,\n",
       " 'whatever': 825,\n",
       " 'evans': 7351,\n",
       " 'peter': 791,\n",
       " 'triangle': 5890,\n",
       " 'bonds': 8924,\n",
       " 'basis': 2826,\n",
       " 'crazy': 902,\n",
       " 'apologies': 9694,\n",
       " 'lifestyle': 4125,\n",
       " 'marvellous': 9561,\n",
       " 'haha': 9437,\n",
       " 'frontal': 6016,\n",
       " 'deservedly': 8803,\n",
       " 'flipping': 8949,\n",
       " 'abraham': 4833,\n",
       " 'deborah': 8490,\n",
       " 'november': 9483,\n",
       " 'understandable': 4355,\n",
       " 'astronaut': 8994,\n",
       " 'iowa': 9710,\n",
       " 'turtle': 7472,\n",
       " 'passengers': 6403,\n",
       " 'draw': 2483,\n",
       " 'families': 2137,\n",
       " 'marty': 4680,\n",
       " 'artist': 1615,\n",
       " 'use': 357,\n",
       " 'chop': 8711,\n",
       " 'seuss': 7918,\n",
       " 'quaint': 7866,\n",
       " 'dangerously': 7653,\n",
       " 'laugh': 457,\n",
       " 'delicious': 6260,\n",
       " 'paxton': 5377,\n",
       " 'din': 5001,\n",
       " 'rolls': 7326,\n",
       " 'wrenching': 6058,\n",
       " 'swiss': 8182,\n",
       " 'shirts': 7860,\n",
       " 'playful': 8252,\n",
       " 'backs': 5414,\n",
       " 'transforms': 8071,\n",
       " 'conflicts': 4536,\n",
       " 'businessman': 4953,\n",
       " 'dash': 7988,\n",
       " 'closest': 4481,\n",
       " 'greats': 9985,\n",
       " 'guests': 5466,\n",
       " 'international': 1947,\n",
       " 'la': 1042,\n",
       " 'pita': 9220,\n",
       " 'saying': 653,\n",
       " 'new': 163,\n",
       " 'doctor': 947,\n",
       " 'darius': 8944,\n",
       " 'candy': 1818,\n",
       " 'exercise': 3426,\n",
       " 'attendant': 8179,\n",
       " 'fall': 788,\n",
       " 'fiasco': 8349,\n",
       " 'talked': 3528,\n",
       " 'carlito': 5853,\n",
       " 'breakfast': 5832,\n",
       " 'common': 1118,\n",
       " 'weary': 6837,\n",
       " 'lived': 1433,\n",
       " 'scripted': 3722,\n",
       " 'hilliard': 9849,\n",
       " 'profanity': 5354,\n",
       " 'sirk': 4532,\n",
       " 'repetitive': 3590,\n",
       " 'prominent': 5657,\n",
       " 'ludicrous': 2737,\n",
       " 'direct': 1485,\n",
       " 'bother': 1393,\n",
       " 'gratuitous': 2150,\n",
       " 'jill': 6123,\n",
       " 'cheadle': 6227,\n",
       " 'hector': 9012,\n",
       " 'masterfully': 6113,\n",
       " 'regardless': 3547,\n",
       " 'breast': 7044,\n",
       " 'ignores': 7308,\n",
       " 'fit': 1160,\n",
       " 'glenn': 3736,\n",
       " 'astonishing': 5102,\n",
       " 'marvelous': 2955,\n",
       " 'underwear': 6157,\n",
       " 'switching': 7912,\n",
       " 'feel': 231,\n",
       " 'spends': 2593,\n",
       " 'squeeze': 9486,\n",
       " 'christianity': 5140,\n",
       " 'avid': 7363,\n",
       " 'accomplishment': 8500,\n",
       " 'church': 1361,\n",
       " 'papers': 6614,\n",
       " 'recipe': 8903,\n",
       " 'inevitable': 3410,\n",
       " 'manipulate': 8736,\n",
       " 'lawrence': 3927,\n",
       " 'portrait': 3165,\n",
       " 'pass': 1313,\n",
       " 'parallels': 6538,\n",
       " 'dialog': 789,\n",
       " 'raid': 7732,\n",
       " 'orchestral': 9906,\n",
       " 'ideal': 4177,\n",
       " 'earns': 8487,\n",
       " 'believability': 8156,\n",
       " 'blaise': 7201,\n",
       " 'celine': 8679,\n",
       " 'date': 1275,\n",
       " 'mum': 6067,\n",
       " 'partial': 9438,\n",
       " 'sucks': 1851,\n",
       " 'prophet': 8721,\n",
       " 'irrational': 8488,\n",
       " 'puzzling': 9246,\n",
       " 'roommates': 8975,\n",
       " 'padding': 8067,\n",
       " 'australian': 2404,\n",
       " 'coppola': 7962,\n",
       " 'credits': 879,\n",
       " 'see': 67,\n",
       " 'deception': 9412,\n",
       " 'triad': 9996,\n",
       " 'popped': 7352,\n",
       " 'trivia': 5531,\n",
       " 'deciding': 6966,\n",
       " 'push': 3574,\n",
       " 'arthur': 1459,\n",
       " 'sheen': 6808,\n",
       " 'wave': 2793,\n",
       " 'options': 9888,\n",
       " 'lubitsch': 7783,\n",
       " 'audiences': 1186,\n",
       " 'bart': 8169,\n",
       " 'x': 1530,\n",
       " 'insomnia': 6638,\n",
       " 'merrill': 9366,\n",
       " 'solved': 7822,\n",
       " 'if': 47,\n",
       " 'convinces': 6158,\n",
       " 'portraying': 2230,\n",
       " 'bolivia': 9254,\n",
       " 'successful': 1087,\n",
       " 'sits': 4457,\n",
       " 'parrot': 7165,\n",
       " 'worrying': 8135,\n",
       " 'underdog': 9364,\n",
       " 'future': 683,\n",
       " 'nora': 7502,\n",
       " 'stalks': 9005,\n",
       " 'anil': 6274,\n",
       " 'drew': 2093,\n",
       " 'history': 468,\n",
       " 'corleone': 9147,\n",
       " 'stupidest': 9235,\n",
       " 'some': 50,\n",
       " 'communication': 7251,\n",
       " 'drugged': 8456,\n",
       " 'natasha': 8468,\n",
       " 'official': 4055,\n",
       " 'cafe': 9963,\n",
       " 'swift': 8740,\n",
       " 'rivalry': 8079,\n",
       " 'decide': 1177,\n",
       " 'there': 41,\n",
       " 'vain': 6033,\n",
       " 'reader': 5076,\n",
       " 'reward': 6139,\n",
       " 'exploring': 5849,\n",
       " 'sugar': 5171,\n",
       " 'chaotic': 7558,\n",
       " 'society': 876,\n",
       " 'temptation': 8619,\n",
       " 'influence': 2358,\n",
       " 'additionally': 6910,\n",
       " 'nonexistent': 8700,\n",
       " 'nerve': 6292,\n",
       " 'advertising': 4571,\n",
       " 'hitchhiker': 9925,\n",
       " 'sensibility': 7237,\n",
       " 'die': 763,\n",
       " 'begun': 6991,\n",
       " 'myers': 4368,\n",
       " 'sooner': 5460,\n",
       " 'advantage': 3055,\n",
       " 'expertly': 6168,\n",
       " 'extraordinarily': 8566,\n",
       " 'else': 327,\n",
       " 'specific': 3351,\n",
       " 'stuck': 1544,\n",
       " 'lone': 4758,\n",
       " 'attenborough': 5329,\n",
       " 'clutter': 8212,\n",
       " 'sentiment': 5175,\n",
       " 'spirits': 4101,\n",
       " 'virus': 3276,\n",
       " 'thieves': 6533,\n",
       " 'touching': 1274,\n",
       " 'eternity': 5687,\n",
       " 'document': 6704,\n",
       " 'maximum': 7417,\n",
       " 'affleck': 5802,\n",
       " 'boat': 2036,\n",
       " 'scare': 2294,\n",
       " 'jealousy': 6514,\n",
       " 'passes': 4069,\n",
       " 'cruella': 8276,\n",
       " 'fashion': 1580,\n",
       " 'luis': 6046,\n",
       " 'nearby': 3967,\n",
       " 'villainous': 7474,\n",
       " 'surprising': 1745,\n",
       " 'jay': 2971,\n",
       " 'whats': 4545,\n",
       " 'forty': 4147,\n",
       " 'depicted': 2363,\n",
       " 'uber': 9127,\n",
       " 'changed': 1170,\n",
       " 'chick': 2185,\n",
       " 'unnatural': 7498,\n",
       " 'revealed': 2012,\n",
       " 'rushes': 9498,\n",
       " 'clockwork': 8571,\n",
       " 'claim': 2276,\n",
       " 'enjoy': 354,\n",
       " 'travelling': 9387,\n",
       " 'fix': 4266,\n",
       " 'staying': 3977,\n",
       " 'generations': 5074,\n",
       " 'wonder': 584,\n",
       " 'brad': 2752,\n",
       " 'given': 346,\n",
       " 'unemployed': 9020,\n",
       " 'diabolical': 9485,\n",
       " 'slice': 5051,\n",
       " 'nailed': 9174,\n",
       " 'rate': 945,\n",
       " 'magical': 2511,\n",
       " 'imagining': 7268,\n",
       " 'wax': 5822,\n",
       " 'until': 364,\n",
       " 'preposterous': 5336,\n",
       " 'luxury': 8316,\n",
       " 'comedians': 5240,\n",
       " 'realizes': 2477,\n",
       " 'rockets': 8449,\n",
       " 'assured': 5617,\n",
       " 'nuclear': 3451,\n",
       " 'vomit': 6806,\n",
       " 'defining': 7809,\n",
       " 'spree': 5787,\n",
       " 'rebecca': 9034,\n",
       " 'misty': 7289,\n",
       " 'compromise': 8829,\n",
       " 'stardom': 6273,\n",
       " 'nations': 5965,\n",
       " 'hunting': 3202,\n",
       " 'road': 1276,\n",
       " 'porn': 1484,\n",
       " 'makers': 1155,\n",
       " 'goofy': 2945,\n",
       " 'refer': 5449,\n",
       " 'yoda': 9766,\n",
       " 'heart': 469,\n",
       " 'meeting': 2152,\n",
       " 'spots': 3207,\n",
       " 'opponents': 8991,\n",
       " 'own': 204,\n",
       " 'e': 954,\n",
       " 'mess': 922,\n",
       " 'verhoeven': 3729,\n",
       " 'credited': 5269,\n",
       " 'alcoholic': 4533,\n",
       " 'written': 392,\n",
       " 'simplistic': 4229,\n",
       " 'roman': 4017,\n",
       " 'hurt': 1432,\n",
       " 'dafoe': 7180,\n",
       " 'rebellious': 6698,\n",
       " 'katie': 8262,\n",
       " 'unconscious': 8867,\n",
       " 'cedric': 7556,\n",
       " 'offerings': 9536,\n",
       " 'hayward': 9123,\n",
       " 'krishna': 9550,\n",
       " 'metal': 2581,\n",
       " 'reminded': 1556,\n",
       " 'sites': 8298,\n",
       " 'we': 70,\n",
       " 'presenting': 5202,\n",
       " 'utterly': 1231,\n",
       " 'utter': 2124,\n",
       " 'behold': 5557,\n",
       " 'sense': 283,\n",
       " 'sleeve': 9206,\n",
       " 'teenager': 2271,\n",
       " 'boys': 960,\n",
       " 'mock': 7153,\n",
       " 'suitably': 5662,\n",
       " 'juliet': 6251,\n",
       " 'paints': 7139,\n",
       " 'shoved': 8314,\n",
       " 'robbery': 4563,\n",
       " 'artistically': 8634,\n",
       " 'jackman': 7491,\n",
       " 'chew': 7503,\n",
       " 'experiment': 2814,\n",
       " 'ruined': 2238,\n",
       " 'also': 83,\n",
       " 'holiday': 3124,\n",
       " 'slick': 4521,\n",
       " 'selected': 6519,\n",
       " 'locales': 9074,\n",
       " 'offense': 8044,\n",
       " 'seen': 109,\n",
       " 'imo': 6356,\n",
       " 'reads': 4508,\n",
       " 'sleepwalkers': 9842,\n",
       " 'tricks': 3307,\n",
       " 'raving': 9582,\n",
       " 'notice': 1477,\n",
       " 'celie': 9721,\n",
       " 'reeves': 5519,\n",
       " 'association': 8858,\n",
       " 'attractive': 1533,\n",
       " 'nd': 3170,\n",
       " 'variations': 9676,\n",
       " 'studying': 5606,\n",
       " 'daily': 2891,\n",
       " 'anytime': 6764,\n",
       " 'stabbed': 7045,\n",
       " 'shoulders': 5161,\n",
       " 'developed': 1368,\n",
       " 'october': 7247,\n",
       " 'blend': 3871,\n",
       " 'postman': 9803,\n",
       " 'lurking': 7192,\n",
       " 'hall': 2281,\n",
       " 'gesture': 9611,\n",
       " 'blamed': 7148,\n",
       " 'finney': 7166,\n",
       " 'figure': 804,\n",
       " 'dedicated': 4299,\n",
       " 'beauty': 904,\n",
       " 'powered': 8420,\n",
       " 'upbeat': 7896,\n",
       " 'devices': 5305,\n",
       " 'piece': 413,\n",
       " 'closed': 4540,\n",
       " 'insightful': 5846,\n",
       " 'elements': 777,\n",
       " 'avoid': 783,\n",
       " 'compliment': 6992,\n",
       " 'explosive': 6882,\n",
       " 'motivation': 3609,\n",
       " 'nostalgia': 4576,\n",
       " 'punches': 5804,\n",
       " 'preston': 5063,\n",
       " 'cent': 9943,\n",
       " 'cab': 7037,\n",
       " 'composition': 7209,\n",
       " 'regarding': 2773,\n",
       " 'breaks': 2002,\n",
       " 'valley': 5010,\n",
       " 'interviews': 2976,\n",
       " 'inconsistent': 5469,\n",
       " 'grotesque': 5229,\n",
       " 'mass': 2921,\n",
       " 'improve': 4374,\n",
       " 'julie': 2769,\n",
       " 'pathetic': 1200,\n",
       " 'stick': 1202,\n",
       " 'surprised': 756,\n",
       " 'basement': 3208,\n",
       " 'monstrous': 9414,\n",
       " 'shah': 6953,\n",
       " 'men': 333,\n",
       " 'distance': 3723,\n",
       " 'villains': 1865,\n",
       " 'caf': 9953,\n",
       " 'guns': 1844,\n",
       " 'barbra': 6414,\n",
       " 'fortunate': 7391,\n",
       " 'botched': 9817,\n",
       " 'heard': 548,\n",
       " 'valuable': 4515,\n",
       " 'further': 1015,\n",
       " 'confronting': 9247,\n",
       " 'daniel': 2146,\n",
       " 'fades': 7715,\n",
       " 'fourth': 2731,\n",
       " 'stephanie': 6458,\n",
       " 'alot': 6916,\n",
       " 'nonetheless': 2894,\n",
       " 'reviewers': 1940,\n",
       " 'harold': 5594,\n",
       " 'shocked': 2379,\n",
       " 'grabbed': 7074,\n",
       " 'frames': 5788,\n",
       " 'mix': 1473,\n",
       " 'orphan': 7803,\n",
       " 'intimate': 4687,\n",
       " 'macmurray': 7872,\n",
       " 'creature': 1582,\n",
       " 'crowd': 2244,\n",
       " 'pulp': 3904,\n",
       " 'bully': 5504,\n",
       " 'holt': 7807,\n",
       " 'rainer': 9148,\n",
       " 'maguire': 8830,\n",
       " 'crap': 583,\n",
       " 'lung': 9190,\n",
       " 'basinger': 5188,\n",
       " 'intend': 7859,\n",
       " 'orgy': 9035,\n",
       " 'delve': 9326,\n",
       " 'heartbreaking': 5388,\n",
       " 'readily': 6833,\n",
       " 'largely': 2234,\n",
       " 'slut': 7724,\n",
       " 'underneath': 5218,\n",
       " 'gram': 8791,\n",
       " 'muddled': 5246,\n",
       " 'stream': 6656,\n",
       " 'clara': 5919,\n",
       " 'famous': 786,\n",
       " 'travel': 2088,\n",
       " 'goodman': 7003,\n",
       " 'hangs': 5878,\n",
       " 'joey': 3464,\n",
       " 'area': 1594,\n",
       " 'attracted': 3602,\n",
       " 'attitudes': 4621,\n",
       " 'hindi': 6339,\n",
       " 'literary': 5247,\n",
       " 'shockingly': 6838,\n",
       " 'minister': 5402,\n",
       " 'encourages': 8828,\n",
       " 'morbid': 5441,\n",
       " 'surprise': 842,\n",
       " 'reeve': 6071,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to vector function\n",
    "\n",
    "Now we can write a function that converts a some text to a word vector. The function will take a string of words as input and return a vector with the words counted up. Here's the general algorithm to do this:\n",
    "\n",
    "* Initialize the word vector with [np.zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html), it should be the length of the vocabulary.\n",
    "* Split the input string of text into a list of words with `.split(' ')`. Again, if you call `.split()` instead, you'll get slightly different results than what we show here.\n",
    "* For each word in that list, increment the element in the index associated with that word, which you get from `word2idx`.\n",
    "\n",
    "**Note:** Since all words aren't in the `vocab` dictionary, you'll get a key error if you run into one of those words. You can use the `.get` method of the `word2idx` dictionary to specify a default returned value when you make a key error. For example, `word2idx.get(word, None)` returns `None` if `word` doesn't exist in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    word_vector = np.zeros(len(vocab), dtype=np.int_)\n",
    "    for word in text.split(' '):\n",
    "        idx = word2idx.get(word, None)\n",
    "        if idx is None:\n",
    "            continue\n",
    "        else:\n",
    "            word_vector[idx] += 1\n",
    "    return np.array(word_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do this right, the following code should return\n",
    "\n",
    "```\n",
    "text_to_vector('The tea is for a party to celebrate '\n",
    "               'the movie so she has no time for a cake')[:65]\n",
    "                   \n",
    "array([0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0])\n",
    "```       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_vector('The tea is for a party to celebrate '\n",
    "               'the movie so she has no time for a cake')[:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run through our entire review data set and convert each review to a word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = np.zeros((len(reviews), len(vocab)), dtype=np.int_)\n",
    "for ii, (_, text) in enumerate(reviews.iterrows()):\n",
    "    word_vectors[ii] = text_to_vector(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18,   9,  27,   1,   4,   4,   6,   4,   0,   2,   2,   5,   0,\n",
       "          4,   1,   0,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  5,   4,   8,   1,   7,   3,   1,   2,   0,   4,   0,   0,   0,\n",
       "          1,   2,   0,   0,   1,   3,   0,   0,   0,   1],\n",
       "       [ 78,  24,  12,   4,  17,   5,  20,   2,   8,   8,   2,   1,   1,\n",
       "          2,   8,   0,   5,   5,   4,   0,   2,   1,   4],\n",
       "       [167,  53,  23,   0,  22,  23,  13,  14,   8,  10,   8,  12,   9,\n",
       "          4,  11,   2,  11,   5,  11,   0,   5,   3,   0],\n",
       "       [ 19,  10,  11,   4,   6,   2,   2,   5,   0,   1,   2,   3,   1,\n",
       "          0,   0,   0,   3,   1,   0,   1,   0,   0,   0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the first 5 word vectors\n",
    "word_vectors[:5, :23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation, Test sets\n",
    "\n",
    "Now that we have the word_vectors, we're ready to split our data into train, validation, and test sets. Remember that we train on the train data, use the validation data to set the hyperparameters, and at the very end measure the network performance on the test data. Here we're using the function `to_categorical` from TFLearn to reshape the target data so that we'll have two output units and can classify with a softmax activation function. We actually won't be creating the validation set here, TFLearn will do that for us later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = (labels=='positive').astype(np.int_)\n",
    "records = len(labels)\n",
    "\n",
    "shuffle = np.arange(records)\n",
    "np.random.shuffle(shuffle)\n",
    "test_fraction = 0.9\n",
    "\n",
    "train_split, test_split = shuffle[:int(records*test_fraction)], shuffle[int(records*test_fraction):]\n",
    "trainX, trainY = word_vectors[train_split,:], to_categorical(Y.values[train_split], 2)\n",
    "testX, testY = word_vectors[test_split,:], to_categorical(Y.values[test_split], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "[TFLearn](http://tflearn.org/) lets you build the network by [defining the layers](http://tflearn.org/layers/core/). \n",
    "\n",
    "### Input layer\n",
    "\n",
    "For the input layer, you just need to tell it how many units you have. For example, \n",
    "\n",
    "```\n",
    "net = tflearn.input_data([None, 100])\n",
    "```\n",
    "\n",
    "would create a network with 100 input units. The first element in the list, `None` in this case, sets the batch size. Setting it to `None` here leaves it at the default batch size.\n",
    "\n",
    "The number of inputs to your network needs to match the size of your data. For this example, we're using 10000 element long vectors to encode our input data, so we need 10000 input units.\n",
    "\n",
    "\n",
    "### Adding layers\n",
    "\n",
    "To add new hidden layers, you use \n",
    "\n",
    "```\n",
    "net = tflearn.fully_connected(net, n_units, activation='ReLU')\n",
    "```\n",
    "\n",
    "This adds a fully connected layer where every unit in the previous layer is connected to every unit in this layer. The first argument `net` is the network you created in the `tflearn.input_data` call. It's telling the network to use the output of the previous layer as the input to this layer. You can set the number of units in the layer with `n_units`, and set the activation function with the `activation` keyword. You can keep adding layers to your network by repeated calling `net = tflearn.fully_connected(net, n_units)`.\n",
    "\n",
    "### Output layer\n",
    "\n",
    "The last layer you add is used as the output layer. There for, you need to set the number of units to match the target data. In this case we are predicting two classes, positive or negative sentiment. You also need to set the activation function so it's appropriate for your model. Again, we're trying to predict if some input data belongs to one of two classes, so we should use softmax.\n",
    "\n",
    "```\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "```\n",
    "\n",
    "### Training\n",
    "To set how you train the network, use \n",
    "\n",
    "```\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "```\n",
    "\n",
    "Again, this is passing in the network you've been building. The keywords: \n",
    "\n",
    "* `optimizer` sets the training method, here stochastic gradient descent\n",
    "* `learning_rate` is the learning rate\n",
    "* `loss` determines how the network error is calculated. In this example, with the categorical cross-entropy.\n",
    "\n",
    "Finally you put all this together to create the model with `tflearn.DNN(net)`. So it ends up looking something like \n",
    "\n",
    "```\n",
    "net = tflearn.input_data([None, 10])                          # Input\n",
    "net = tflearn.fully_connected(net, 5, activation='ReLU')      # Hidden\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')   # Output\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "model = tflearn.DNN(net)\n",
    "```\n",
    "\n",
    "> **Exercise:** Below in the `build_model()` function, you'll put together the network using TFLearn. You get to choose how many layers to use, how many hidden units, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network building\n",
    "def build_model():\n",
    "    # This resets all parameters and variables, leave this here\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Inputs\n",
    "    net = tflearn.input_data([None, 10000])\n",
    "\n",
    "    # Hidden layer(s)\n",
    "    net = tflearn.fully_connected(net, 200, activation='ReLU')\n",
    "    net = tflearn.fully_connected(net, 25, activation='ReLU')\n",
    "\n",
    "    # Output layer\n",
    "    net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "    net = tflearn.regression(net, optimizer='sgd', \n",
    "                             learning_rate=0.1, \n",
    "                             loss='categorical_crossentropy')\n",
    "    \n",
    "    model = tflearn.DNN(net)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intializing the model\n",
    "\n",
    "Next we need to call the `build_model()` function to actually build the model. In my solution I haven't included any arguments to the function, but you can add arguments so you can change parameters in the model if you want.\n",
    "\n",
    "> **Note:** You might get a bunch of warnings here. TFLearn uses a lot of deprecated code in TensorFlow. Hopefully it gets updated to the new TensorFlow version soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "Now that we've constructed the network, saved as the variable `model`, we can fit it to the data. Here we use the `model.fit` method. You pass in the training features `trainX` and the training targets `trainY`. Below I set `validation_set=0.1` which reserves 10% of the data set as the validation set. You can also set the batch size and number of epochs with the `batch_size` and `n_epoch` keywords, respectively. Below is the code to fit our the network to our word vectors.\n",
    "\n",
    "You can rerun `model.fit` to train the network further if you think you can increase the validation accuracy. Remember, all hyperparameter adjustments must be done using the validation set. **Only use the test set after you're completely done training the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 15899  | total loss: \u001b[1m\u001b[32m1.38629\u001b[0m\u001b[0m | time: 14.546s\n",
      "| SGD | epoch: 100 | loss: 1.38629 - acc: 0.4302 -- iter: 20224/20250\n",
      "Training Step: 15900  | total loss: \u001b[1m\u001b[32m1.38629\u001b[0m\u001b[0m | time: 15.743s\n",
      "| SGD | epoch: 100 | loss: 1.38629 - acc: 0.4270 | val_loss: 1.38629 - val_acc: 0.4062 -- iter: 20250/20250\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(trainX, trainY, validation_set=0.1, show_metric=True, batch_size=128, n_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "After you're satisified with your hyperparameters, you can run the network on the test set to measure it's performance. Remember, *only do this after finalizing the hyperparameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.4052\n"
     ]
    }
   ],
   "source": [
    "predictions = (np.array(model.predict(testX))[:,0] >= 0.5).astype(np.int_)\n",
    "test_accuracy = np.mean(predictions == testY[:,0], axis=0)\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out your own text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function that uses your model to predict sentiment\n",
    "def test_sentence(sentence):\n",
    "    positive_prob = model.predict([text_to_vector(sentence.lower())])[0][1]\n",
    "    print('Sentence: {}'.format(sentence))\n",
    "    print('P(positive) = {:.3f} :'.format(positive_prob), \n",
    "          'Positive' if positive_prob > 0.5 else 'Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Moonlight is by far the best movie of 2016.\n",
      "P(positive) = 0.500 : Negative\n",
      "Sentence: It's amazing anyone could be talented enough to make something this spectacularly awful\n",
      "P(positive) = 0.500 : Positive\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Moonlight is by far the best movie of 2016.\"\n",
    "test_sentence(sentence)\n",
    "\n",
    "sentence = \"It's amazing anyone could be talented enough to make something this spectacularly awful\"\n",
    "test_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
